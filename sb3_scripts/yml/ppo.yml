SimEnv:
  normalize: false
#  n_envs: 32
  n_timesteps: 25000
  policy: 'MultiInputPolicy'
  n_steps: 512
  batch_size: 128
  gae_lambda: 0.9
  gamma: 0.99
  n_epochs: 10
  vf_coef: 0.5
  ent_coef: 0.00001
#  use_sde: True
  max_grad_norm: 0.8
  learning_rate: 0.0005  # Use a constant value for now, schedule can be added in code
#  sde_sample_freq: 4
  clip_range: 0.3
  policy_kwargs: "dict(
                    ortho_init=False,
                    activation_fn=nn.ReLU,
                    net_arch=dict(pi=[128,128], vf=[128,128])
                  )"
  callback:
<<<<<<< HEAD
    - rl_scripts.helpers.callback_helpers.GetModelParams:
<<<<<<< HEAD
        verbose: 1
=======
        verbose: 1
>>>>>>> 1f52b86dd1dd359a55ed3e3a65460946d498524c
=======
    - reinforcement_learning.utils.callbacks.GetModelParams:
        verbose: 1
>>>>>>> 2fefd9cb6e1093671afd8551d30b85445d76d9d5
