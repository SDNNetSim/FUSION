SimEnv:
  normalize: true
  n_timesteps: 500000
  policy: "MultiInputPolicy"
  learning_rate: 0.0005
  buffer_size: 100000
  learning_starts: 5000
  batch_size: 128                  # QRDQN benefits from larger batches
  gamma: 0.97                      # Slightly lower for better convergence under bursty rewards
  tau: 1.0                         # Hard target update; could reduce for soft updates
  train_freq: 1
  gradient_steps: 8                # QRDQN can benefit from more gradient steps
  target_update_interval: 3000
  exploration_fraction: 0.1
  exploration_final_eps: 0.01
  max_grad_norm: 10
  verbose: 1
  policy_kwargs: "dict(net_arch=[256, 128, 64])"
