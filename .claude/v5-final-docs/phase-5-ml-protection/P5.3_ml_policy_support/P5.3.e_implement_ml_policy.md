# Task ID: P5.3.e - Implement MLControlPolicy

**Sub-phase:** P5.3
**Scope:** Phase 5 - ML Control + Protection only
**Task type:** wiring-plan

---

## Purpose

Implement the complete `fusion/policies/ml_policy.py` file containing MLControlPolicy and supporting classes from the designs in P5.3.b, P5.3.c, and P5.3.d.

---

## Context to load before running this task

- `.claude/v5-final-docs/phase-5-ml-protection/P5.3_ml_policy_support/P5.3.b_design_ml_control_policy.md`
- `.claude/v5-final-docs/phase-5-ml-protection/P5.3_ml_policy_support/P5.3.c_design_fallback_mechanism.md`
- `.claude/v5-final-docs/phase-5-ml-protection/P5.3_ml_policy_support/P5.3.d_design_feature_engineering.md`

---

## Outputs

### 1. Create `fusion/policies/ml_policy.py`

```python
"""
ML-based control policy using pre-trained models.

This module provides MLControlPolicy for deploying pre-trained ML models
(PyTorch, scikit-learn, ONNX) as path selection policies. Includes:

- Multi-framework model loading
- Automatic fallback to heuristics on errors
- Feature engineering compatible with RL training
- Action masking for feasibility constraints

Example:
    >>> policy = MLControlPolicy(
    ...     model_path="models/bc_policy.pt",
    ...     device="cpu",
    ...     fallback_type="first_feasible",
    ... )
    >>> action = policy.select_action(request, options, network_state)
"""

from __future__ import annotations

import logging
from enum import Enum
from pathlib import Path
from typing import TYPE_CHECKING, Any

import numpy as np

if TYPE_CHECKING:
    from fusion.domain.network_state import NetworkState
    from fusion.domain.request import Request
    from fusion.rl.adapter import PathOption

logger = logging.getLogger(__name__)


class ModelType(Enum):
    """Supported ML model types."""

    PYTORCH = "pytorch"
    SKLEARN = "sklearn"
    ONNX = "onnx"

    @classmethod
    def from_path(cls, path: str) -> "ModelType":
        """
        Infer model type from file extension.

        Args:
            path: Model file path

        Returns:
            Inferred ModelType

        Raises:
            ValueError: If extension is not recognized
        """
        ext = Path(path).suffix.lower()
        extension_map = {
            ".pt": cls.PYTORCH,
            ".pth": cls.PYTORCH,
            ".joblib": cls.SKLEARN,
            ".pkl": cls.SKLEARN,
            ".onnx": cls.ONNX,
        }
        if ext not in extension_map:
            raise ValueError(
                f"Unknown model extension: {ext}. "
                f"Supported: {list(extension_map.keys())}"
            )
        return extension_map[ext]


class FeatureBuilder:
    """
    Build feature vectors for ML model inference.

    Creates fixed-size feature vectors from Request and PathOption
    inputs, with padding for variable numbers of paths.
    """

    FEATURES_PER_PATH = 4
    MAX_BANDWIDTH_GBPS = 1000.0
    MAX_WEIGHT_KM = 10000.0
    MAX_SLOTS = 100.0

    def __init__(self, k_paths: int = 5) -> None:
        """
        Initialize feature builder.

        Args:
            k_paths: Expected number of path options
        """
        self.k_paths = k_paths
        self._feature_size = 1 + k_paths * self.FEATURES_PER_PATH

    @property
    def feature_size(self) -> int:
        """Total size of feature vector."""
        return self._feature_size

    def build(
        self,
        request: Request,
        options: list[PathOption],
        network_state: NetworkState,
    ) -> np.ndarray:
        """Build feature vector from inputs."""
        features = []

        # Request-level features
        features.append(request.bandwidth_gbps / self.MAX_BANDWIDTH_GBPS)

        # Per-path features (padded to k_paths)
        for i in range(self.k_paths):
            if i < len(options):
                opt = options[i]
                features.extend([
                    opt.weight_km / self.MAX_WEIGHT_KM,
                    opt.congestion,
                    1.0 if opt.is_feasible else 0.0,
                    (opt.slots_needed or 0) / self.MAX_SLOTS,
                ])
            else:
                # Padding: no path, high congestion, not feasible, no slots
                features.extend([0.0, 1.0, 0.0, 0.0])

        return np.array(features, dtype=np.float32)


class MLControlPolicy:
    """
    ML-based control policy using a pre-trained model.

    Supports PyTorch, scikit-learn, and ONNX models with automatic
    fallback to heuristic policies on errors.

    Implements the ControlPolicy protocol.

    Attributes:
        model_path: Path to the saved model file
        device: Inference device ('cpu' or 'cuda')
        model_type: Type of model
        model: Loaded model object
        fallback: Fallback policy for errors
        k_paths: Expected number of path options
    """

    def __init__(
        self,
        model_path: str,
        device: str = "cpu",
        model_type: str | ModelType | None = None,
        fallback_policy: Any | None = None,
        fallback_type: str = "first_feasible",
        k_paths: int = 5,
    ) -> None:
        """
        Initialize ML policy with pre-trained model.

        Args:
            model_path: Path to saved model file
            device: Inference device ('cpu' or 'cuda')
            model_type: Model type. If None, inferred from extension.
            fallback_policy: Explicit fallback policy instance
            fallback_type: Fallback type if policy not provided:
                'first_feasible', 'shortest_feasible',
                'least_congested', 'random'
            k_paths: Expected number of path options

        Raises:
            FileNotFoundError: If model file doesn't exist
            ValueError: If model type cannot be determined
        """
        self.model_path = model_path
        self.device = self._resolve_device(device)
        self.k_paths = k_paths

        # Resolve model type
        if model_type is None:
            self.model_type = ModelType.from_path(model_path)
        elif isinstance(model_type, str):
            self.model_type = ModelType(model_type)
        else:
            self.model_type = model_type

        # Load model
        self.model = self._load_model(model_path)

        # Set up feature builder
        self._feature_builder = FeatureBuilder(k_paths=k_paths)

        # Set up fallback
        if fallback_policy is not None:
            self.fallback = fallback_policy
        else:
            self.fallback = self._create_fallback(fallback_type)

        # Statistics tracking
        self._total_calls = 0
        self._fallback_calls = 0
        self._error_types: dict[str, int] = {}

        logger.info(
            f"MLControlPolicy initialized: {self.model_type.value} model "
            f"on {self.device}, fallback={self.fallback.get_name()}"
        )

    def _resolve_device(self, device: str) -> str:
        """Resolve device string, checking CUDA availability."""
        if device == "cuda":
            try:
                import torch
                if torch.cuda.is_available():
                    return "cuda"
                logger.warning("CUDA requested but not available, using CPU")
            except ImportError:
                logger.warning("PyTorch not installed, using CPU")
        return "cpu"

    def _create_fallback(self, fallback_type: str) -> Any:
        """Create fallback policy from type string."""
        from fusion.policies.heuristic_policy import (
            FirstFeasiblePolicy,
            LeastCongestedPolicy,
            RandomFeasiblePolicy,
            ShortestFeasiblePolicy,
        )

        fallback_map = {
            "first_feasible": FirstFeasiblePolicy,
            "shortest_feasible": ShortestFeasiblePolicy,
            "least_congested": LeastCongestedPolicy,
            "random": RandomFeasiblePolicy,
        }

        if fallback_type not in fallback_map:
            raise ValueError(
                f"Unknown fallback type: {fallback_type}. "
                f"Options: {list(fallback_map.keys())}"
            )

        return fallback_map[fallback_type]()

    def _load_model(self, path: str) -> Any:
        """Load model from file based on model type."""
        if not Path(path).exists():
            raise FileNotFoundError(f"Model file not found: {path}")

        if self.model_type == ModelType.PYTORCH:
            return self._load_pytorch(path)
        elif self.model_type == ModelType.SKLEARN:
            return self._load_sklearn(path)
        elif self.model_type == ModelType.ONNX:
            return self._load_onnx(path)
        else:
            raise ValueError(f"Unknown model type: {self.model_type}")

    def _load_pytorch(self, path: str) -> Any:
        """Load PyTorch model."""
        import torch
        model = torch.load(path, map_location=self.device)
        model.eval()
        logger.debug(f"Loaded PyTorch model from {path}")
        return model

    def _load_sklearn(self, path: str) -> Any:
        """Load scikit-learn model."""
        import joblib
        model = joblib.load(path)
        logger.debug(f"Loaded sklearn model from {path}")
        return model

    def _load_onnx(self, path: str) -> Any:
        """Load ONNX model as inference session."""
        import onnxruntime as ort
        session = ort.InferenceSession(path)
        logger.debug(f"Loaded ONNX model from {path}")
        return session

    def select_action(
        self,
        request: Request,
        options: list[PathOption],
        network_state: NetworkState,
    ) -> int:
        """
        Select action using the trained model.

        On any error, falls back to the fallback policy.

        Args:
            request: The incoming request
            options: Available path options
            network_state: Current network state

        Returns:
            Selected path index, or -1 if no valid action
        """
        self._total_calls += 1

        # Early return for empty options
        if not options:
            return -1

        try:
            # Build features
            features = self._feature_builder.build(
                request, options, network_state
            )

            # Run inference
            raw_output = self._predict(features)

            # Apply mask and select
            action = self._apply_mask_and_select(raw_output, options)

            # Validate action
            if self._is_valid_action(action, options):
                return action

            logger.warning(
                f"ML model selected invalid action {action}, using fallback"
            )
            return self._use_fallback(
                request, options, network_state, "invalid_action"
            )

        except ImportError as e:
            logger.error(f"ML framework import error: {e}")
            return self._use_fallback(
                request, options, network_state, "import_error"
            )

        except RuntimeError as e:
            logger.warning(f"Model runtime error: {e}")
            return self._use_fallback(
                request, options, network_state, "runtime_error"
            )

        except Exception as e:
            logger.warning(f"Unexpected ML error: {e}")
            return self._use_fallback(
                request, options, network_state, "unexpected_error"
            )

    def _predict(self, features: np.ndarray) -> np.ndarray:
        """Run model inference on features."""
        if self.model_type == ModelType.PYTORCH:
            return self._predict_pytorch(features)
        elif self.model_type == ModelType.SKLEARN:
            return self._predict_sklearn(features)
        elif self.model_type == ModelType.ONNX:
            return self._predict_onnx(features)
        else:
            raise ValueError(f"Unknown model type: {self.model_type}")

    def _predict_pytorch(self, features: np.ndarray) -> np.ndarray:
        """PyTorch inference."""
        import torch
        with torch.no_grad():
            tensor = torch.FloatTensor(features).unsqueeze(0).to(self.device)
            output = self.model(tensor)
            return output.cpu().numpy()[0]

    def _predict_sklearn(self, features: np.ndarray) -> np.ndarray:
        """scikit-learn inference."""
        X = features.reshape(1, -1)
        if hasattr(self.model, 'predict_proba'):
            return self.model.predict_proba(X)[0]
        return self.model.predict(X)

    def _predict_onnx(self, features: np.ndarray) -> np.ndarray:
        """ONNX inference."""
        input_name = self.model.get_inputs()[0].name
        X = features.reshape(1, -1).astype(np.float32)
        output = self.model.run(None, {input_name: X})
        return output[0][0]

    def _apply_mask_and_select(
        self,
        raw_output: np.ndarray,
        options: list[PathOption],
    ) -> int:
        """Apply feasibility mask and select best action."""
        # Build mask from options
        mask = np.array([opt.is_feasible for opt in options], dtype=bool)

        # Handle scalar output
        if raw_output.ndim == 0:
            action = int(raw_output.item())
            return action if action < len(mask) and mask[action] else -1

        # Handle size mismatch
        if len(raw_output) > len(options):
            raw_output = raw_output[: len(options)]

        # Apply mask
        masked = raw_output.copy()
        masked[~mask[: len(masked)]] = float('-inf')

        # Check if any valid action
        if np.all(np.isinf(masked)):
            return -1

        return int(np.argmax(masked))

    def _is_valid_action(self, action: int, options: list[PathOption]) -> bool:
        """Check if action is valid and feasible."""
        if action < 0 or action >= len(options):
            return False
        return options[action].is_feasible

    def _use_fallback(
        self,
        request: Request,
        options: list[PathOption],
        network_state: NetworkState,
        reason: str = "unknown",
    ) -> int:
        """Use fallback policy and track statistics."""
        self._fallback_calls += 1
        self._error_types[reason] = self._error_types.get(reason, 0) + 1
        return self.fallback.select_action(request, options, network_state)

    def update(self, request: Request, action: int, reward: float) -> None:
        """
        Update policy based on experience.

        ML policies use pre-trained models and don't learn online.
        This is a no-op to satisfy the ControlPolicy protocol.
        """
        pass

    def get_name(self) -> str:
        """Return policy name for logging."""
        return f"MLControlPolicy({self.model_type.value})"

    @property
    def fallback_rate(self) -> float:
        """Percentage of calls that used fallback."""
        if self._total_calls == 0:
            return 0.0
        return self._fallback_calls / self._total_calls

    def get_stats(self) -> dict[str, Any]:
        """Get fallback statistics."""
        return {
            "total_calls": self._total_calls,
            "fallback_calls": self._fallback_calls,
            "fallback_rate": self.fallback_rate,
            "error_types": self._error_types.copy(),
        }

    def reset_stats(self) -> None:
        """Reset fallback statistics."""
        self._total_calls = 0
        self._fallback_calls = 0
        self._error_types.clear()
```

### 2. Update `fusion/policies/__init__.py`

```python
"""
FUSION Control Policies Package.

This package provides path selection policies implementing the ControlPolicy
protocol. Available policy types:

Heuristic Policies:
    - FirstFeasiblePolicy: Selects first feasible path
    - ShortestFeasiblePolicy: Selects shortest feasible path
    - LeastCongestedPolicy: Selects least congested path
    - RandomFeasiblePolicy: Random selection among feasible
    - LoadBalancedPolicy: Weighted length + congestion

ML Policies:
    - MLControlPolicy: Pre-trained model deployment

Example:
    >>> from fusion.policies import MLControlPolicy, FirstFeasiblePolicy
    >>> policy = MLControlPolicy("model.pt", fallback_policy=FirstFeasiblePolicy())
"""

from fusion.interfaces.control_policy import ControlPolicy, PolicyAction
from fusion.policies.heuristic_policy import (
    FirstFeasiblePolicy,
    HeuristicPolicy,
    LeastCongestedPolicy,
    LoadBalancedPolicy,
    RandomFeasiblePolicy,
    ShortestFeasiblePolicy,
)
from fusion.policies.ml_policy import FeatureBuilder, MLControlPolicy, ModelType

__all__ = [
    # Protocol
    "ControlPolicy",
    "PolicyAction",
    # Base class
    "HeuristicPolicy",
    # Heuristic policies
    "FirstFeasiblePolicy",
    "ShortestFeasiblePolicy",
    "LeastCongestedPolicy",
    "RandomFeasiblePolicy",
    "LoadBalancedPolicy",
    # ML policies
    "MLControlPolicy",
    "ModelType",
    "FeatureBuilder",
]
```

### 3. Directory Structure After Task

```
fusion/
├── interfaces/
│   ├── __init__.py
│   └── control_policy.py
├── policies/
│   ├── __init__.py              # UPDATED with ML exports
│   ├── heuristic_policy.py
│   └── ml_policy.py             # NEW: MLControlPolicy
└── rl/
    └── adapter.py
```

---

## Verification Commands

```bash
# Import test
python -c "from fusion.policies import MLControlPolicy, ModelType, FeatureBuilder; print('OK')"

# Model type inference
python -c "from fusion.policies.ml_policy import ModelType; print(ModelType.from_path('model.pt'))"

# Type checking
mypy fusion/policies/ml_policy.py

# Linting
ruff check fusion/policies/ml_policy.py
```

---

## Verification Checklist

- [ ] ModelType enum with from_path() method
- [ ] FeatureBuilder with configurable k_paths
- [ ] MLControlPolicy supports PyTorch, sklearn, ONNX
- [ ] Fallback mechanism with statistics tracking
- [ ] Device resolution with CUDA check
- [ ] All imports are lazy (in methods, not module level)
- [ ] Comprehensive logging
- [ ] All exports added to __init__.py
- [ ] mypy and ruff pass

---

## Next Task

Proceed to **P5.3.f** to create the verification test suite.
