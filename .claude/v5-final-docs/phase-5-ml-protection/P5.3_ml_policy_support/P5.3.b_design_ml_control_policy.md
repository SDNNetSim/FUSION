# Task ID: P5.3.b - Design MLControlPolicy Class

**Sub-phase:** P5.3
**Scope:** Phase 5 - ML Control + Protection only
**Task type:** design

---

## Purpose

Design the complete `MLControlPolicy` class that deploys pre-trained ML models for path selection, supporting multiple frameworks and providing robust error handling.

---

## Context to load before running this task

- `.claude/v5-final-docs/phase-5-ml-protection/P5.3_ml_policy_support/P5.3.shared_context_model_formats.md`
- `.claude/v5-final-docs/phase-5-ml-protection/P5.3_ml_policy_support/P5.3.a_context_extraction_ml_patterns.md`
- `fusion/interfaces/control_policy.py`
- `fusion/policies/heuristic_policy.py`

---

## Outputs

### 1. MLControlPolicy Class Design

```python
"""
ML-based control policy using pre-trained models.

This module provides MLControlPolicy for deploying pre-trained ML models
(PyTorch, scikit-learn, ONNX) as path selection policies.
"""

from __future__ import annotations

import logging
from enum import Enum
from pathlib import Path
from typing import TYPE_CHECKING, Any

import numpy as np

if TYPE_CHECKING:
    from fusion.domain.network_state import NetworkState
    from fusion.domain.request import Request
    from fusion.rl.adapter import PathOption

logger = logging.getLogger(__name__)


class ModelType(Enum):
    """Supported ML model types."""

    PYTORCH = "pytorch"
    SKLEARN = "sklearn"
    ONNX = "onnx"

    @classmethod
    def from_path(cls, path: str) -> "ModelType":
        """Infer model type from file extension."""
        ext = Path(path).suffix.lower()
        if ext in (".pt", ".pth"):
            return cls.PYTORCH
        elif ext in (".joblib", ".pkl"):
            return cls.SKLEARN
        elif ext == ".onnx":
            return cls.ONNX
        else:
            raise ValueError(f"Unknown model extension: {ext}")


class MLControlPolicy:
    """
    ML-based control policy using a pre-trained model.

    Supports multiple model frameworks:
    - PyTorch neural networks (.pt, .pth files)
    - scikit-learn classifiers (.joblib, .pkl files)
    - ONNX models (.onnx files)

    Includes automatic fallback to a heuristic policy on model errors.

    This class implements the ControlPolicy protocol.

    Attributes:
        model_path: Path to the saved model file
        device: Inference device ('cpu' or 'cuda')
        model_type: Type of model (pytorch, sklearn, onnx)
        model: Loaded model object
        fallback: Fallback policy for error cases
        k_paths: Expected number of path options

    Example:
        >>> policy = MLControlPolicy(
        ...     model_path="models/bc_policy.pt",
        ...     device="cpu",
        ...     model_type="pytorch",
        ... )
        >>> action = policy.select_action(request, options, network_state)
    """

    def __init__(
        self,
        model_path: str,
        device: str = "cpu",
        model_type: str | ModelType | None = None,
        fallback_policy: Any | None = None,
        k_paths: int = 5,
    ) -> None:
        """
        Initialize ML policy with pre-trained model.

        Args:
            model_path: Path to saved model file
            device: Inference device ('cpu' or 'cuda')
            model_type: Model type. If None, inferred from file extension.
            fallback_policy: Policy to use on model failure. If None,
                uses FirstFeasiblePolicy.
            k_paths: Expected number of path options (for feature padding)

        Raises:
            FileNotFoundError: If model file doesn't exist
            ValueError: If model type cannot be determined
        """
        self.model_path = model_path
        self.device = self._resolve_device(device)
        self.k_paths = k_paths

        # Resolve model type
        if model_type is None:
            self.model_type = ModelType.from_path(model_path)
        elif isinstance(model_type, str):
            self.model_type = ModelType(model_type)
        else:
            self.model_type = model_type

        # Load model
        self.model = self._load_model(model_path)

        # Set up fallback
        if fallback_policy is None:
            from fusion.policies.heuristic_policy import FirstFeasiblePolicy
            self.fallback = FirstFeasiblePolicy()
        else:
            self.fallback = fallback_policy

        logger.info(
            f"MLControlPolicy initialized: {self.model_type.value} model "
            f"on {self.device}, fallback={self.fallback.get_name()}"
        )

    def _resolve_device(self, device: str) -> str:
        """Resolve device string, checking CUDA availability."""
        if device == "cuda":
            try:
                import torch
                if torch.cuda.is_available():
                    return "cuda"
                logger.warning("CUDA requested but not available, using CPU")
            except ImportError:
                logger.warning("PyTorch not installed, using CPU")
        return "cpu"

    def _load_model(self, path: str) -> Any:
        """
        Load model from file based on model type.

        Returns:
            Loaded model object ready for inference
        """
        if not Path(path).exists():
            raise FileNotFoundError(f"Model file not found: {path}")

        if self.model_type == ModelType.PYTORCH:
            return self._load_pytorch(path)
        elif self.model_type == ModelType.SKLEARN:
            return self._load_sklearn(path)
        elif self.model_type == ModelType.ONNX:
            return self._load_onnx(path)
        else:
            raise ValueError(f"Unknown model type: {self.model_type}")

    def _load_pytorch(self, path: str) -> Any:
        """Load PyTorch model."""
        import torch
        model = torch.load(path, map_location=self.device)
        model.eval()
        logger.debug(f"Loaded PyTorch model from {path}")
        return model

    def _load_sklearn(self, path: str) -> Any:
        """Load scikit-learn model."""
        import joblib
        model = joblib.load(path)
        logger.debug(f"Loaded sklearn model from {path}")
        return model

    def _load_onnx(self, path: str) -> Any:
        """Load ONNX model as inference session."""
        import onnxruntime as ort
        session = ort.InferenceSession(path)
        logger.debug(f"Loaded ONNX model from {path}")
        return session

    def select_action(
        self,
        request: Request,
        options: list[PathOption],
        network_state: NetworkState,
    ) -> int:
        """
        Select action using the trained model.

        Builds feature vector from inputs, runs model inference,
        applies action masking, and returns selected action.

        On any error, falls back to the fallback policy.

        Args:
            request: The incoming request
            options: Available path options
            network_state: Current network state

        Returns:
            Selected path index, or -1 if no valid action
        """
        try:
            # Build features
            features = self._build_features(request, options, network_state)

            # Run inference
            raw_output = self._predict(features)

            # Apply mask and select
            action = self._apply_mask_and_select(raw_output, options)

            # Validate action
            if self._is_valid_action(action, options):
                return action

            logger.warning(
                f"ML model returned invalid action {action}, using fallback"
            )
            return self.fallback.select_action(request, options, network_state)

        except Exception as e:
            logger.warning(f"ML model error: {e}, using fallback")
            return self.fallback.select_action(request, options, network_state)

    def _predict(self, features: np.ndarray) -> np.ndarray:
        """
        Run model inference on features.

        Returns:
            Model output (logits, Q-values, or probabilities)
        """
        if self.model_type == ModelType.PYTORCH:
            return self._predict_pytorch(features)
        elif self.model_type == ModelType.SKLEARN:
            return self._predict_sklearn(features)
        elif self.model_type == ModelType.ONNX:
            return self._predict_onnx(features)
        else:
            raise ValueError(f"Unknown model type: {self.model_type}")

    def _predict_pytorch(self, features: np.ndarray) -> np.ndarray:
        """PyTorch inference."""
        import torch
        with torch.no_grad():
            tensor = torch.FloatTensor(features).unsqueeze(0).to(self.device)
            output = self.model(tensor)
            return output.cpu().numpy()[0]

    def _predict_sklearn(self, features: np.ndarray) -> np.ndarray:
        """scikit-learn inference."""
        X = features.reshape(1, -1)
        if hasattr(self.model, 'predict_proba'):
            return self.model.predict_proba(X)[0]
        return self.model.predict(X)

    def _predict_onnx(self, features: np.ndarray) -> np.ndarray:
        """ONNX inference."""
        input_name = self.model.get_inputs()[0].name
        X = features.reshape(1, -1).astype(np.float32)
        output = self.model.run(None, {input_name: X})
        return output[0][0]

    def _build_features(
        self,
        request: Request,
        options: list[PathOption],
        network_state: NetworkState,
    ) -> np.ndarray:
        """
        Build feature vector from request and path options.

        Feature layout matches RL training observation space.
        """
        features = []

        # Request-level features
        features.append(request.bandwidth_gbps / 1000.0)

        # Per-path features (padded to k_paths)
        for i in range(self.k_paths):
            if i < len(options):
                opt = options[i]
                features.extend([
                    opt.weight_km / 10000.0,
                    opt.congestion,
                    1.0 if opt.is_feasible else 0.0,
                    (opt.slots_needed or 0) / 100.0,
                ])
            else:
                # Padding for missing paths
                features.extend([0.0, 1.0, 0.0, 0.0])

        return np.array(features, dtype=np.float32)

    def _apply_mask_and_select(
        self,
        raw_output: np.ndarray,
        options: list[PathOption],
    ) -> int:
        """
        Apply feasibility mask and select best action.

        Returns:
            Selected action index, or -1 if all masked
        """
        # Build mask from options
        mask = np.array([opt.is_feasible for opt in options], dtype=bool)

        # Handle different output shapes
        if raw_output.ndim == 0:
            # Scalar output (direct action prediction)
            action = int(raw_output.item())
            return action if action < len(mask) and mask[action] else -1

        if len(raw_output) != len(options):
            # Output size mismatch - truncate or use available
            raw_output = raw_output[: len(options)]
            if len(raw_output) < len(options):
                # Pad with -inf
                padded = np.full(len(options), float('-inf'))
                padded[: len(raw_output)] = raw_output
                raw_output = padded

        # Apply mask
        masked = raw_output.copy()
        masked[~mask] = float('-inf')

        # Check if any valid action
        if np.all(np.isinf(masked)):
            return -1

        return int(np.argmax(masked))

    def _is_valid_action(self, action: int, options: list[PathOption]) -> bool:
        """Check if action is valid and feasible."""
        if action < 0 or action >= len(options):
            return False
        return options[action].is_feasible

    def update(self, request: Request, action: int, reward: float) -> None:
        """
        Update policy based on experience.

        ML policies use pre-trained models and don't learn online.
        This is a no-op to satisfy the ControlPolicy protocol.
        """
        pass

    def get_name(self) -> str:
        """Return policy name for logging."""
        return f"MLControlPolicy({self.model_type.value})"
```

### 2. Design Rationale Table

| Decision | Rationale |
|----------|-----------|
| **ModelType enum** | Type-safe model type handling with auto-detection from extension |
| **Device resolution** | Graceful fallback to CPU if CUDA unavailable |
| **Fallback policy** | Ensures simulation never fails due to model errors |
| **Lazy imports** | Only import torch/onnx when needed (reduce startup time) |
| **Feature padding** | Fixed-size input for models trained with fixed k_paths |
| **Logging** | Debug/info/warning levels for different events |
| **update() no-op** | Pre-trained models don't learn online |

### 3. Integration with ControlPolicy

```python
from fusion.interfaces.control_policy import ControlPolicy

# MLControlPolicy satisfies ControlPolicy protocol
policy = MLControlPolicy("model.pt")
assert isinstance(policy, ControlPolicy)  # Would fail - need explicit check

# For Protocol compliance, the class has:
# - select_action(request, options, network_state) -> int
# - update(request, action, reward) -> None
```

---

## Verification

- [ ] ModelType enum handles all supported formats
- [ ] Device resolution checks CUDA availability
- [ ] Model loading works for PyTorch, sklearn, ONNX
- [ ] Feature building matches RL observation space
- [ ] Action masking enforces feasibility
- [ ] Fallback policy used on errors
- [ ] Comprehensive logging included
- [ ] Protocol methods implemented

---

## Test Cases to Implement

```python
def test_model_type_from_path():
    """Should infer model type from file extension."""
    assert ModelType.from_path("model.pt") == ModelType.PYTORCH
    assert ModelType.from_path("model.pth") == ModelType.PYTORCH
    assert ModelType.from_path("model.joblib") == ModelType.SKLEARN
    assert ModelType.from_path("model.pkl") == ModelType.SKLEARN
    assert ModelType.from_path("model.onnx") == ModelType.ONNX

def test_fallback_on_missing_model():
    """Should raise FileNotFoundError for missing model."""
    with pytest.raises(FileNotFoundError):
        MLControlPolicy("nonexistent.pt")

def test_fallback_on_inference_error():
    """Should use fallback when model raises error."""
    # Test with mock model that raises
    ...

def test_action_masking():
    """Should respect is_feasible when selecting action."""
    ...
```

---

## Next Task

Proceed to **P5.3.c** to design the fallback mechanism in detail.
