# Shared Context: Existing Policy Patterns

**Purpose:** Document existing policy implementations to inform ControlPolicy design
**Used by:** P5.1.a, P5.1.b, P5.1.c tasks

---

## Sources

- `fusion/modules/rl/policies/base.py` - PathPolicy abstract interface
- `fusion/modules/rl/policies/ksp_ff_policy.py` - First-fit heuristic
- `fusion/modules/rl/policies/one_plus_one_policy.py` - 1+1 protection heuristic
- `fusion/modules/rl/policies/bc_policy.py` - Behavior Cloning policy
- `fusion/modules/rl/policies/iql_policy.py` - Implicit Q-Learning policy
- `fusion/modules/rl/utils/action_masking.py` - Action masking utilities

---

## Current PathPolicy Interface

```python
from abc import ABC, abstractmethod
from typing import Any

class PathPolicy(ABC):
    """Abstract base class for path selection policies."""

    @abstractmethod
    def select_path(self, state: dict[str, Any], action_mask: list[bool]) -> int:
        """
        Select a path index based on current state.

        Args:
            state: Dictionary containing observation features
            action_mask: Boolean mask of valid actions (True = valid)

        Returns:
            Path index (0 to K-1) or -1 if all masked
        """
        pass

    def get_name(self) -> str:
        """Return policy name for logging."""
        return self.__class__.__name__
```

---

## State Dictionary Format

The legacy `state` dictionary has this structure:

```python
state = {
    'src': int,                    # Source node index
    'dst': int,                    # Destination node index
    'slots_needed': int,           # Required spectrum slots
    'est_remaining_time': float,   # Estimated request duration
    'is_disaster': int,            # 0 or 1 flag
    'paths': [                     # List of K path features
        {
            'path_hops': int,              # Number of hops
            'min_residual_slots': int,     # Minimum available slots on path
            'frag_indicator': float,       # Fragmentation metric (0-1)
            'failure_mask': int,           # 0 or 1 if path affected by failure
            'dist_to_disaster_centroid': int,  # Distance metric
        },
        # ... K paths total
    ]
}
```

---

## Action Mask Convention

```python
action_mask: list[bool] = [True, False, True, False, False]
# Index 0: Valid action
# Index 1: Invalid (path not feasible)
# Index 2: Valid action
# etc.
```

The policy must:
1. Only select indices where `action_mask[i] == True`
2. Return `-1` if all masks are `False`

---

## Existing Policy Implementations

### KSPFFPolicy (First-Fit)

```python
class KSPFFPolicy(PathPolicy):
    """K-Shortest Path First Fit - selects first feasible path."""

    def select_path(self, state: dict[str, Any], action_mask: list[bool]) -> int:
        for i, is_valid in enumerate(action_mask):
            if is_valid:
                return i
        return -1
```

### OnePlusOnePolicy (Protection Heuristic)

```python
class OnePlusOnePolicy(PathPolicy):
    """Selects path pair for 1+1 protection."""

    def select_path(self, state: dict[str, Any], action_mask: list[bool]) -> int:
        # Complex logic considering primary + backup feasibility
        # Returns path index for best disjoint pair
        ...
```

### BCPolicy (Behavior Cloning)

```python
class BCPolicy(PathPolicy):
    """Neural network trained via behavior cloning."""

    def __init__(self, model_path: str, device: str = "cpu"):
        self.model = self._load_model(model_path)
        self.device = device

    def select_path(self, state: dict[str, Any], action_mask: list[bool]) -> int:
        features = self._extract_features(state)
        logits = self.model(features)
        masked_logits = self._apply_mask(logits, action_mask)
        return int(torch.argmax(masked_logits))
```

### IQLPolicy (Implicit Q-Learning)

```python
class IQLPolicy(PathPolicy):
    """Neural network trained via Implicit Q-Learning."""

    # Similar structure to BCPolicy
    # Uses Q-values for action selection
    ...
```

---

## Mapping to ControlPolicy

| PathPolicy | ControlPolicy |
|------------|---------------|
| `select_path(state, mask)` | `select_action(request, options, network_state)` |
| No update method | `update(request, action, reward)` |
| `state` dict | `Request` + `PathOption` list |
| `action_mask` list | `PathOption.is_feasible` per option |
| Returns int | Returns int |

### Key Differences

1. **Typed inputs**: ControlPolicy uses domain objects (Request, PathOption) instead of dict
2. **Feasibility in options**: `is_feasible` is a field on PathOption, not a separate mask
3. **Learning support**: `update()` method enables online learning policies
4. **NetworkState access**: Policies can inspect network state (read-only)

---

## Action Masking Utilities

From `fusion/modules/rl/utils/action_masking.py`:

```python
def apply_action_mask(logits: np.ndarray, mask: list[bool]) -> np.ndarray:
    """Set invalid action logits to -inf."""
    masked = logits.copy()
    for i, valid in enumerate(mask):
        if not valid:
            masked[i] = float('-inf')
    return masked

def get_feasible_indices(mask: list[bool]) -> list[int]:
    """Return list of valid action indices."""
    return [i for i, valid in enumerate(mask) if valid]
```

---

## Design Implications for ControlPolicy

1. **Maintain compatibility**: ControlPolicy should support similar selection patterns
2. **Simplify masking**: Feasibility embedded in PathOption eliminates separate mask
3. **Add learning**: `update()` method for RL/online learning policies
4. **Protocol typing**: Use Protocol for structural typing (no inheritance required)
5. **Frozen options**: PathOption is immutable to prevent mutation during selection

---

## Migration Path

Existing policies can be wrapped to implement ControlPolicy:

```python
class LegacyPolicyAdapter(ControlPolicy):
    """Adapts legacy PathPolicy to ControlPolicy interface."""

    def __init__(self, legacy_policy: PathPolicy):
        self._policy = legacy_policy

    def select_action(
        self, request: Request, options: list[PathOption], network_state: NetworkState
    ) -> int:
        state = self._build_state_dict(request, options, network_state)
        mask = [opt.is_feasible for opt in options]
        return self._policy.select_path(state, mask)

    def update(self, request: Request, action: int, reward: float) -> None:
        pass  # Legacy policies don't learn
```

This adapter pattern allows gradual migration without breaking existing code.
