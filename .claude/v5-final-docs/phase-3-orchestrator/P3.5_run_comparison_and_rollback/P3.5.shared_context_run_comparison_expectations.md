# P3.5 Shared Context: Run Comparison Expectations

## Purpose

This document defines the expectations and tolerances for comparing the legacy and new simulation paths.

## Source Files

- `tests/run_comparison.py`
- `.claude/v4-docs/migration/phase_3_orchestrator.md` (P3.5 section)

## Comparison Philosophy

The new orchestrator path should produce **statistically equivalent** results to the legacy path, not necessarily identical results.

### Why Not Identical?

1. **Floating point precision**: Minor differences in calculation order
2. **Algorithm implementation**: Adapters may have slight variations
3. **State management**: NetworkState vs network_spectrum_dict
4. **Timing**: Different code paths may affect RNG consumption

### What Matters

- Overall blocking behavior should match
- Resource utilization patterns should be similar
- No systematic bias in either direction

## Tolerance Definitions

### Primary Metrics (Must Pass)

| Metric | Tolerance | Rationale |
|--------|-----------|-----------|
| Blocking probability | 2% absolute | Core metric for correctness |
| Bit-rate blocking | 2% absolute | Weighted blocking metric |

Example:
- Legacy blocking: 5.0%
- New blocking: 6.5%
- Difference: 1.5% (PASS - within 2%)

### Secondary Metrics (Informational)

| Metric | Expected | Notes |
|--------|----------|-------|
| Block reason distribution | Similar | May vary due to evaluation order |
| Modulation distribution | Similar | Should match modulation selection |
| Average path length | Within 5% | Minor variations acceptable |
| Average hops | Within 5% | Minor variations acceptable |

## Test Configurations

### Recommended Test Matrix

| Config | Topology | Requests | Erlangs | Iterations |
|--------|----------|----------|---------|------------|
| Quick | NSFNet | 1,000 | 100 | 1 |
| Standard | NSFNet | 10,000 | 200 | 3 |
| Full | NSFNet | 100,000 | 150-300 | 5 |
| USNet | USNet | 10,000 | 200 | 3 |

### Feature Combinations

Test both paths with:
- Grooming enabled/disabled
- SNR enabled/disabled
- Slicing enabled/disabled
- Protection enabled/disabled

## Expected Behavior

### Blocking Probability Curve

Both paths should produce similar blocking curves:

```
Blocking
Prob.
  |
  |                    *
  |                 *
  |              *
  |           *
  |        *
  |     *
  |  *
  +-------------------------> Erlangs

Legend: Both paths should follow same curve shape
```

### Block Reason Distribution

```
Legacy:             New Path:
distance: 10%       distance: 11%
congestion: 85%     congestion: 84%
xt_threshold: 5%    xt_threshold: 5%

These are acceptable variations.
```

## Pass/Fail Criteria

### PASS Conditions

1. Blocking probability difference < 2%
2. Bit-rate blocking difference < 2%
3. No crashes or errors
4. All requests processed

### FAIL Conditions

1. Blocking probability difference >= 2%
2. Bit-rate blocking difference >= 2%
3. Simulation crashes
4. Missing or corrupted stats

### INVESTIGATE Conditions

1. Block reason distribution significantly different
2. Resource usage patterns diverge
3. Path length/hops statistics diverge significantly

## Debugging Deviations

### If Blocking Too High (New Path)

1. Check if grooming is working correctly
2. Verify routing finds same paths
3. Check spectrum allocation logic
4. Verify SNR validation thresholds

### If Blocking Too Low (New Path)

1. Check if rejections are being counted
2. Verify block reasons are tracked
3. Check stats update is called

### Logging for Debug

Enable debug logging:
```bash
FUSION_LOG_LEVEL=DEBUG USE_ORCHESTRATOR=1 python tests/run_comparison.py
```

Check for:
- Pipeline calls logged
- Result values logged
- Stats updates logged

## Statistical Significance

### Sample Size Recommendations

| Confidence | Min Requests | Iterations |
|------------|--------------|------------|
| 90% | 5,000 | 3 |
| 95% | 10,000 | 5 |
| 99% | 50,000 | 10 |

### Confidence Interval

The comparison should use confidence intervals:
```python
# If 95% CI of difference includes 0, PASS
# If 95% CI of difference excludes 2%, PASS
# Otherwise, INVESTIGATE
```

## Historical Baseline

### Expected Blocking Rates

| Topology | Erlangs | Expected BP |
|----------|---------|-------------|
| NSFNet | 100 | 1-3% |
| NSFNet | 200 | 10-15% |
| NSFNet | 300 | 25-35% |
| USNet | 200 | 8-12% |

If either path deviates significantly from these ranges, investigate.

## Non-Equivalence Indicators (V3 Compliance)

### Systematic Bias Detection

A systematic bias exists when one path consistently produces higher or lower blocking across multiple test runs.

```python
def detect_systematic_bias(results: list[tuple[float, float]]) -> bool:
    """
    Detect systematic bias in comparison results.

    Args:
        results: List of (legacy_bp, new_bp) tuples from multiple runs

    Returns:
        True if systematic bias detected
    """
    legacy_higher = sum(1 for l, n in results if l > n)
    new_higher = sum(1 for l, n in results if n > l)
    total = len(results)

    # Bias if one path is higher >80% of the time
    if legacy_higher / total > 0.8 or new_higher / total > 0.8:
        return True

    return False
```

**Action on Bias Detection**: Investigate systematically. The new path may have a bug that consistently affects results in one direction.

### Distribution Shape Comparison

Block reason distributions should have similar "shape" even if exact counts differ:

```python
def compare_distribution_shape(
    legacy: dict[str, int],
    new: dict[str, int],
) -> bool:
    """
    Compare distribution shapes.

    Returns True if shapes are similar (same dominant category).
    """
    # Normalize to percentages
    legacy_total = sum(legacy.values()) or 1
    new_total = sum(new.values()) or 1

    legacy_pct = {k: v / legacy_total for k, v in legacy.items()}
    new_pct = {k: v / new_total for k, v in new.items()}

    # Check dominant category matches
    legacy_dominant = max(legacy_pct, key=legacy_pct.get)
    new_dominant = max(new_pct, key=new_pct.get)

    if legacy_dominant != new_dominant:
        return False  # Different dominant block reason

    # Check relative ordering preserved
    legacy_order = sorted(legacy_pct.keys(), key=lambda k: legacy_pct.get(k, 0), reverse=True)
    new_order = sorted(new_pct.keys(), key=lambda k: new_pct.get(k, 0), reverse=True)

    # Top 2 reasons should be in same order
    if legacy_order[:2] != new_order[:2]:
        return False

    return True
```

### Secondary Metric Thresholds

| Metric | Warning Threshold | Investigate Threshold |
|--------|-------------------|----------------------|
| Block reason chi-square | p < 0.1 | p < 0.01 |
| Path length mean diff | > 3% | > 5% |
| Hop count mean diff | > 0.3 hops | > 0.5 hops |
| Modulation distribution | chi-sq p < 0.1 | chi-sq p < 0.01 |

### RNG Consumption Patterns

Different code paths may consume random numbers differently:

```
Legacy path: RNG calls for route selection, spectrum selection
New path: May call RNG in different order

Result:
- Even with same seed, requests may get different random values
- This is acceptable if overall distribution is preserved
- Not acceptable if it causes systematic difference
```

### Feature Flag Specific Checks

| Feature Flag | Additional Check |
|--------------|------------------|
| grooming_enabled | Compare groom success rate |
| snr_enabled | Compare SNR failure rate |
| slicing_enabled | Compare slice count distribution |
| protection_enabled | Compare protection failure rate |

## Environment Variables

```bash
# Enable new path
USE_ORCHESTRATOR=1

# Set seed for reproducibility
FUSION_SEED=42

# Enable debug logging
FUSION_LOG_LEVEL=DEBUG

# Set number of requests
FUSION_NUM_REQUESTS=10000
```

## Comparison Report Template

```
============================================================
PHASE 3 COMPARISON REPORT
============================================================

Primary Metrics:
  Legacy blocking probability: X.XX%
  New blocking probability:    X.XX%
  Absolute difference:         X.XX%
  Status: PASS / FAIL

Secondary Metrics:
  Block reason distribution:   SIMILAR / DIVERGENT
  Path length (mean):          Legacy=X.X km, New=X.X km
  Hop count (mean):            Legacy=X.X, New=X.X
  Modulation distribution:     SIMILAR / DIVERGENT

Bias Analysis:
  Systematic bias detected:    YES / NO
  Direction (if bias):         Legacy Higher / New Higher

Feature-Specific:
  Grooming success rate:       Legacy=X%, New=X%
  SNR failure rate:            Legacy=X%, New=X%

Verdict: PASS / FAIL / INVESTIGATE
============================================================
```
