# P4.4 Shared Context - Parity Metrics and Tolerances

**Purpose:** Define the metrics, tolerances, and comparison methodology for validating parity between `GeneralSimEnv` and `UnifiedSimEnv`.

## Source Documentation

- `.claude/v4-docs/testing/phase_4_testing.md`
- `.claude/v4-docs/architecture/rl_integration.md`

---

## 1. Primary Metrics

### Blocking Probability

The key performance metric for optical network simulation.

```
Blocking Probability = (Blocked Requests) / (Total Requests)
```

**Tolerance**: Within 5% of legacy environment

**Calculation Method**:
```python
def compute_blocking_probability(env, episodes=10, seed_base=0):
    """Compute average blocking probability over multiple episodes."""
    block_counts = []
    total_counts = []

    for ep in range(episodes):
        env.reset(seed=seed_base + ep)
        blocked = 0
        total = 0

        done = False
        while not done:
            action = select_action(env)  # Heuristic or random
            _, reward, terminated, truncated, _ = env.step(action)
            done = terminated or truncated

            total += 1
            if reward < 0:  # Blocking
                blocked += 1

        block_counts.append(blocked)
        total_counts.append(total)

    return sum(block_counts) / sum(total_counts)
```

### Reward Distribution

Compare cumulative rewards over episodes.

```python
def compute_episode_rewards(env, episodes=10, seed_base=0):
    """Collect episode reward statistics."""
    episode_rewards = []

    for ep in range(episodes):
        env.reset(seed=seed_base + ep)
        total_reward = 0

        done = False
        while not done:
            action = select_action(env)
            _, reward, terminated, truncated, _ = env.step(action)
            done = terminated or truncated
            total_reward += reward

        episode_rewards.append(total_reward)

    return {
        "mean": np.mean(episode_rewards),
        "std": np.std(episode_rewards),
        "min": np.min(episode_rewards),
        "max": np.max(episode_rewards),
    }
```

---

## 2. Secondary Metrics

### Action Mask Agreement

For the same state, action masks should match.

```python
def compare_action_masks(legacy_env, unified_env, seed):
    """Compare action masks at each step."""
    legacy_env.reset(seed=seed)
    unified_env.reset(seed=seed)

    # Note: Legacy env may not have action mask in info
    # Compare observation-based feasibility instead

    legacy_obs, _ = legacy_env.reset(seed=seed)
    unified_obs, unified_info = unified_env.reset(seed=seed)

    # Compare is_feasible (if present in legacy)
    # or compare via observation features
```

### Step-by-Step Reward Comparison

Compare reward at each step with identical actions.

```python
def compare_step_rewards(legacy_env, unified_env, seed, num_steps=50):
    """Compare step-by-step rewards."""
    legacy_env.reset(seed=seed)
    unified_env.reset(seed=seed)

    rewards_match = True

    for step in range(num_steps):
        action = 0  # Same action for both

        _, r_legacy, term_l, _, _ = legacy_env.step(action)
        _, r_unified, term_u, _, _ = unified_env.step(action)

        if r_legacy != r_unified:
            rewards_match = False
            print(f"Step {step}: legacy={r_legacy}, unified={r_unified}")

        if term_l or term_u:
            break

    return rewards_match
```

---

## 3. Tolerance Thresholds

| Metric | Tolerance | Justification |
|--------|-----------|---------------|
| Blocking Probability | Within 5% | Accounts for minor algorithmic differences |
| Episode Reward Mean | Within 10% | Allows for observation differences |
| Episode Reward Std | Within 20% | Higher variance acceptable |
| Determinism | Exact match | Same seed must produce same sequence |

### Tolerance Calculation

```python
def within_tolerance(legacy_value, unified_value, tolerance_pct):
    """Check if values are within tolerance."""
    if legacy_value == 0:
        return unified_value == 0
    diff_pct = abs(unified_value - legacy_value) / abs(legacy_value) * 100
    return diff_pct <= tolerance_pct
```

---

## 4. Comparison Methodology

### Test Protocol

1. **Determinism Test**: Same seed produces same request sequence
2. **Single-Step Test**: Same action produces same immediate result
3. **Episode Test**: Same policy produces similar episode statistics
4. **Statistical Test**: Multiple episodes produce comparable distributions

### Policy Selection for Comparison

Use consistent policies for fair comparison:

```python
# Option 1: Always select first valid path (heuristic)
def first_valid_policy(obs, info):
    mask = info.get("action_mask", np.ones(k, dtype=bool))
    valid = np.where(mask)[0]
    return valid[0] if len(valid) > 0 else 0

# Option 2: Random selection
def random_policy(obs, info):
    return np.random.randint(0, k)

# Option 3: Trained model
def model_policy(obs, info, model):
    action, _ = model.predict(obs)
    return action
```

---

## 5. Known Difference Categories

### 5.1 Intentional Improvements

| Difference | Legacy | Unified | Impact |
|------------|--------|---------|--------|
| Spectrum Check | mock_handle_arrival | Real pipeline | More accurate |
| SNR Validation | May skip | Always runs | More correct |
| Grooming | Separate logic | Unified | Consistent |
| Action Masking | Not in info | In info dict | Better learning |

### 5.2 Observation Differences

| Feature | Legacy | Unified | Notes |
|---------|--------|---------|-------|
| `paths_cong` | Present | Renamed to `congestion` | Breaking change |
| `is_feasible` | Not present | Present | New feature |
| Normalization | Custom | Standardized | May differ |

### 5.3 Behavioral Differences

| Behavior | Legacy | Unified | Notes |
|----------|--------|---------|-------|
| Feasibility source | Mock | Real pipeline | Core difference |
| Release timing | Approximate | Exact | Minor impact |
| State representation | Dict-based | Object-based | Internal |

---

## 6. Reporting Template

### Parity Report Structure

```markdown
# RL Environment Parity Report

## Test Configuration
- Date: YYYY-MM-DD
- Legacy Version: X.Y.Z
- Unified Version: X.Y.Z
- Episodes: 10
- Seeds: 0-9
- Policy: first_valid

## Results Summary

### Blocking Probability
- Legacy: X.XX%
- Unified: Y.YY%
- Difference: Z.ZZ%
- Status: PASS/FAIL (threshold: 5%)

### Episode Rewards
- Legacy Mean: X.XX (std: Y.YY)
- Unified Mean: X.XX (std: Y.YY)
- Difference: Z.ZZ%
- Status: PASS/FAIL (threshold: 10%)

### Determinism
- Request sequences match: YES/NO
- Observation shapes match: YES/NO
- Status: PASS/FAIL

## Differences Found

### Intentional Differences
1. [List intentional differences]

### Unexpected Differences
1. [List if any]

## Recommendation
- [ ] Ready for production
- [ ] Needs investigation
- [ ] Rollback recommended
```

---

## 7. Automated Comparison Script

```python
# scripts/compare_rl_envs.py

def main():
    """Run parity comparison between environments."""
    legacy_env = create_legacy_env(config)
    unified_env = create_unified_env(config)

    results = {
        "determinism": test_determinism(legacy_env, unified_env),
        "blocking": compare_blocking_probability(legacy_env, unified_env),
        "rewards": compare_reward_distributions(legacy_env, unified_env),
    }

    report = generate_report(results)
    print(report)

    # Return exit code based on results
    return 0 if all_passed(results) else 1
```

---

## 8. Failure Investigation Procedure

If parity tests fail:

1. **Identify scope**: Which metric failed?
2. **Isolate step**: Find first divergence point
3. **Compare states**: Dump observations and masks at divergence
4. **Root cause**: Determine if intentional or bug
5. **Document or fix**: Add to differences doc or fix code
6. **Rollback if needed**: Use legacy env while investigating
