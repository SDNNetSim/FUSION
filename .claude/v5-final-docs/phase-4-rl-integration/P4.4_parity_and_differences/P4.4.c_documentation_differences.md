# Task ID: P4.4.c - Documentation: RL Environment Differences

**Sub-phase:** P4.4
**Scope:** Phase 4 - RL Integration only
**Task type:** documentation

## Purpose

Create comprehensive documentation of differences between `GeneralSimEnv` and `UnifiedSimEnv`, including intentional changes, behavioral differences, and impact on trained models.

## Context to load before running this task

- `.claude/v5-final-docs/phase-4-rl-integration/P4.4_parity_and_differences/P4.4.shared_context_parity_metrics.md`
- `.claude/v5-final-docs/phase-4-rl-integration/P4.2_unified_env/P4.2.a_context_extraction_general_sim_env.md`
- `.claude/v5-final-docs/phase-4-rl-integration/P4.3_migrate_experiments/P4.3.c_deprecation_plan.md`

## Outputs

### 1. Differences Documentation

Create `docs/migration/rl_differences.md`:

```markdown
# RL Environment Differences: GeneralSimEnv vs UnifiedSimEnv

This document details the differences between the legacy `GeneralSimEnv`
and the new `UnifiedSimEnv`. Understanding these differences is important
for migrating existing RL experiments and interpreting behavioral changes.

## Summary of Changes

| Category | Impact | Migration Action |
|----------|--------|------------------|
| Observation space | Medium | May need retraining |
| Feasibility checking | High | Improved accuracy |
| Action masking | Medium | Better learning |
| Reward computation | Low | Compatible |
| State management | Internal | No action needed |

## Detailed Differences

### 1. Observation Space Changes

#### Renamed Keys

| Legacy Name | Unified Name | Notes |
|-------------|--------------|-------|
| `paths_cong` | `congestion` | Clearer naming |

#### New Keys

| Key | Type | Description |
|-----|------|-------------|
| `is_feasible` | Box(0,1) | Binary feasibility per path |

#### Removed Keys

None. All legacy observation keys have equivalents in unified env.

#### Shape Compatibility

Observation shapes are identical for common keys:
- `source`: (num_nodes,)
- `destination`: (num_nodes,)
- `slots_needed`: (k_paths,)
- `path_lengths`: (k_paths,)
- `congestion`/`paths_cong`: (k_paths,)
- `available_slots`: (k_paths,)

#### Value Range Changes

| Key | Legacy Range | Unified Range | Notes |
|-----|--------------|---------------|-------|
| `slots_needed` | [-1, max] | [-1, max] | Identical |
| `path_lengths` | [0, max_hops] | [0, max_hops] | Identical |
| `congestion` | [0, 1] | [0, 1] | Identical |
| `available_slots` | [0, 1] | [0, 1] | Identical |

### 2. Feasibility Checking

This is the most significant difference between environments.

#### Legacy (GeneralSimEnv)

```
Feasibility = mock_handle_arrival()
    → Creates temporary SpectrumAssignment object
    → Checks spectrum availability
    → Does NOT interact with real simulation
    → May diverge from actual allocation behavior
```

#### Unified (UnifiedSimEnv)

```
Feasibility = spectrum_pipeline.find_spectrum(allocate=False)
    → Uses SAME pipeline as actual allocation
    → Includes SNR validation (if enabled)
    → Includes band filtering (if multi-band)
    → Guaranteed consistent with allocation
```

#### Impact

- **More accurate feasibility**: Unified env may block paths that
  legacy env considered feasible (or vice versa)
- **Better action masking**: Masks reflect true allocation potential
- **Training implications**: Policies may learn different strategies

#### Metrics Affected

| Metric | Expected Change |
|--------|-----------------|
| Blocking probability | May differ by 2-5% |
| Valid action rate | May increase (more accurate masks) |
| False positives | Eliminated (no mock divergence) |

### 3. Action Masking

#### Legacy (GeneralSimEnv)

- Action mask NOT included in `info` dict
- `reset()` returns `(obs, {})`
- `step()` returns `(obs, reward, term, trunc, {})`
- Agent learns feasibility through reward signal

#### Unified (UnifiedSimEnv)

- Action mask included in `info["action_mask"]`
- `reset()` returns `(obs, {"action_mask": mask})`
- `step()` returns `(obs, reward, term, trunc, {"action_mask": mask})`
- Agent can use mask for safe exploration

#### Using Action Masking

```python
# With SB3 MaskablePPO
from sb3_contrib import MaskablePPO
from fusion.rl.environments import ActionMaskWrapper

env = UnifiedSimEnv(config)
env = ActionMaskWrapper(env)

model = MaskablePPO("MultiInputPolicy", env)
model.learn(total_timesteps=100_000)

# During inference
obs, info = env.reset()
action, _ = model.predict(obs, action_masks=env.action_masks())
```

#### Impact on Training

- **Faster convergence**: Agent avoids invalid actions
- **Better exploration**: Focus on feasible actions
- **Changed reward distribution**: Fewer blocking penalties

### 4. Reward Computation

#### Legacy (GeneralSimEnv)

```python
if was_allocated:
    reward = engine_props["reward"]  # e.g., +1.0
else:
    reward = engine_props["penalty"]  # e.g., -1.0
```

#### Unified (UnifiedSimEnv)

```python
if result.success:
    reward = config.rl_success_reward  # e.g., +1.0
    if result.is_groomed:
        reward += config.rl_grooming_bonus  # e.g., +0.1
    if result.is_sliced:
        reward += config.rl_slicing_penalty  # e.g., -0.05
else:
    reward = config.rl_block_penalty  # e.g., -1.0
```

#### Impact

- **Grooming/slicing awareness**: Unified env can reward/penalize grooming and slicing
- **Configurable rewards**: Easier to tune via config
- **Backward compatible**: With same config values, rewards match

### 5. State Management

#### Legacy (GeneralSimEnv)

- Uses `engine_props` dict for state
- Uses `SDNProps` object for allocation
- Manual state synchronization

#### Unified (UnifiedSimEnv)

- Uses `NetworkState` object
- Uses `AllocationResult` for outcomes
- Automatic state management via orchestrator

#### Impact

- **Internal change only**: Does not affect agent interface
- **More robust**: Fewer state synchronization bugs
- **Better debugging**: Clear state ownership

### 6. Release Handling

#### Legacy (GeneralSimEnv)

- Releases processed via `rl_help_obj.handle_releases()`
- Timing may be approximate

#### Unified (UnifiedSimEnv)

- Releases processed via `engine.process_releases_until(time)`
- Exact timing based on request arrival time

#### Impact

- **Minor**: May affect utilization at specific time points
- **More accurate**: Spectrum freed at exact release time

## Model Compatibility

### Pre-trained Models

Models trained with `GeneralSimEnv` may not work optimally with
`UnifiedSimEnv` due to:

1. **Observation key rename** (`paths_cong` -> `congestion`)
2. **Additional observation key** (`is_feasible`)
3. **Different feasibility patterns**
4. **Action masking (if using MaskablePPO)**

### Migration Options

#### Option 1: Observation Adapter (Quick)

Create an adapter that transforms observations:

```python
class ObservationAdapter(gym.Wrapper):
    def reset(self, **kwargs):
        obs, info = self.env.reset(**kwargs)
        return self._adapt_obs(obs), info

    def step(self, action):
        obs, r, term, trunc, info = self.env.step(action)
        return self._adapt_obs(obs), r, term, trunc, info

    def _adapt_obs(self, obs):
        # Rename for legacy model compatibility
        adapted = dict(obs)
        adapted["paths_cong"] = adapted.pop("congestion")
        # Remove is_feasible if model doesn't expect it
        adapted.pop("is_feasible", None)
        return adapted
```

#### Option 2: Retrain (Recommended)

Retrain models with `UnifiedSimEnv` for:

- Better accuracy (real feasibility)
- Action masking support
- Future compatibility

#### Option 3: Hybrid Approach

Use adapter for evaluation, retrain for production.

## Performance Comparison

### Training Speed

| Environment | Episodes/sec | Notes |
|-------------|--------------|-------|
| Legacy | X | Mock feasibility is fast |
| Unified | Y | Real pipeline may be slower |

If performance is critical, profile both environments.

### Learning Curves

Expect different learning curves due to:

- Action masking (faster learning in unified)
- Different feasibility (different blocking patterns)
- More accurate rewards

## Recommendation Summary

| Use Case | Recommended Environment |
|----------|------------------------|
| New experiments | UnifiedSimEnv |
| Evaluating legacy models | GeneralSimEnv (with adapter) |
| Production training | UnifiedSimEnv |
| Quick prototyping | Either (unified preferred) |
| Parity-critical | Both with comparison |

## FAQ

### Q: Why is my blocking rate different?

The unified env uses real spectrum pipeline, which may have different
feasibility results than the mock in legacy env. This is expected and
represents more accurate simulation.

### Q: Can I use my old model with the new env?

Yes, with the observation adapter (Option 1 above). However, performance
may degrade due to different feasibility patterns. Consider retraining.

### Q: Is the unified env slower?

It may be slightly slower due to using real pipelines. For most use cases,
the difference is negligible. If concerned, benchmark both.

### Q: Should I use action masking?

Yes, if using compatible algorithms (MaskablePPO). It improves learning
by preventing the agent from selecting infeasible actions.

### Q: What if I find a bug in unified env?

Report it and use the rollback procedure to switch to legacy env while
the bug is investigated. See `docs/migration/rl_to_unified_env.md`.
```

### 2. Update Migration Guide

Add to `docs/migration/rl_to_unified_env.md`:

```markdown
## Key Differences

See [RL Environment Differences](rl_differences.md) for detailed comparison.

Summary:
- Observation key `paths_cong` renamed to `congestion`
- New observation key `is_feasible` added
- Action mask now in `info["action_mask"]`
- Feasibility from real spectrum pipeline (more accurate)
```

### 3. Changelog Entry

Add to `CHANGELOG.md`:

```markdown
### Changed (RL)
- Observation key `paths_cong` renamed to `congestion` in UnifiedSimEnv
- Action masking now provided via `info["action_mask"]`
- Feasibility checking uses real spectrum pipeline instead of mock

### Added (RL)
- `is_feasible` observation feature showing path feasibility
- `ActionMaskWrapper` for SB3 MaskablePPO integration
- Grooming/slicing reward bonuses/penalties
```

## Verification

- [ ] rl_differences.md created
- [ ] All observation differences documented
- [ ] Feasibility difference explained
- [ ] Action masking difference explained
- [ ] Model compatibility options provided
- [ ] Migration guide updated
- [ ] Changelog entry added

## Next Task

Proceed to **P4.4.d** to define rollback procedures.
