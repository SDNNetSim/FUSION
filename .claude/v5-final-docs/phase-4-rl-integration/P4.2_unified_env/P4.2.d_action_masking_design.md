# Task ID: P4.2.d - Design Action Masking Integration

**Sub-phase:** P4.2
**Scope:** Phase 4 - RL Integration only
**Task type:** design

## Purpose

Design the action masking system that prevents RL agents from selecting infeasible paths. This includes the mask generation in `UnifiedSimEnv` and the `ActionMaskWrapper` for SB3 integration.

## Context to load before running this task

- `.claude/v5-final-docs/phase-4-rl-integration/P4.2_unified_env/P4.2.shared_context_env_requirements.md`
- `.claude/v5-final-docs/phase-4-rl-integration/P4.1_rl_adapter/P4.1.b_design_pathoption.md`
- `fusion/modules/rl/policies/action_masking.py` (legacy implementation)

## Outputs

### 1. Action Mask Flow

```
UnifiedSimEnv.reset() / step()
         │
         ▼
adapter.get_path_options(request, network_state)
         │
         ├─── routing_pipeline.find_routes()
         │         └─── Returns k candidate paths
         │
         └─── spectrum_pipeline.find_spectrum(allocate=False)
                   └─── Returns is_free for each path
         │
         ▼
list[PathOption] with is_feasible field
         │
         ▼
adapter.get_action_mask(options)
         │
         └─── Returns np.ndarray[bool] of shape (k_paths,)
         │
         ▼
info["action_mask"] returned to agent
         │
         ▼
MaskablePPO uses mask to filter logits
```

### 2. Mask Generation in Adapter

Already defined in P4.1.b:

```python
def compute_action_mask(options: list[PathOption], k_paths: int) -> np.ndarray:
    """Generate action mask from path options.

    Args:
        options: List of PathOption instances
        k_paths: Total number of possible actions

    Returns:
        Boolean array where True = action is valid (feasible path)
    """
    mask = np.zeros(k_paths, dtype=bool)
    for opt in options:
        if opt.path_index < k_paths:
            mask[opt.path_index] = opt.is_feasible
    return mask
```

### 3. Mask in Info Dict

`UnifiedSimEnv._build_info()`:

```python
def _build_info(self) -> dict[str, Any]:
    """Build info dict with action mask.

    The action_mask key is required for SB3 MaskablePPO integration.
    """
    if self._current_request is None:
        # Terminal state - all actions masked
        mask = np.zeros(self._config.k_paths, dtype=bool)
    else:
        mask = self._adapter.get_action_mask(self._current_options)

    return {
        "action_mask": mask,
        "request_index": self._request_index,
        "total_requests": self._total_requests,
    }
```

### 4. ActionMaskWrapper for SB3

Create `fusion/rl/environments/wrappers.py`:

```python
"""Environment wrappers for RL integration."""

from typing import Any, Callable
import gymnasium as gym
import numpy as np


class ActionMaskWrapper(gym.Wrapper):
    """Wrapper that exposes action mask for SB3 MaskablePPO.

    SB3-Contrib's MaskablePPO requires a specific interface for action
    masking. This wrapper provides compatibility with that interface.

    Usage:
        env = UnifiedSimEnv(config)
        env = ActionMaskWrapper(env)
        model = MaskablePPO("MultiInputPolicy", env)
        model.learn(total_timesteps=10000)

    Note:
        This wrapper caches the last action mask for the action_masks()
        method, which SB3 calls during action selection.
    """

    def __init__(self, env: gym.Env) -> None:
        """Initialize wrapper.

        Args:
            env: Environment with action_mask in info dict
        """
        super().__init__(env)
        self._last_action_mask: np.ndarray | None = None

    def reset(self, **kwargs) -> tuple[Any, dict]:
        """Reset and cache action mask."""
        obs, info = self.env.reset(**kwargs)
        self._last_action_mask = info.get("action_mask")
        return obs, info

    def step(self, action: int) -> tuple[Any, float, bool, bool, dict]:
        """Step and cache action mask."""
        obs, reward, terminated, truncated, info = self.env.step(action)
        self._last_action_mask = info.get("action_mask")
        return obs, reward, terminated, truncated, info

    def action_masks(self) -> np.ndarray:
        """Return current action mask.

        This method is called by SB3 MaskablePPO during action selection.

        Returns:
            Boolean array of valid actions

        Raises:
            RuntimeError: If called before reset()
        """
        if self._last_action_mask is None:
            raise RuntimeError("Must call reset() before action_masks()")
        return self._last_action_mask
```

### 5. Alternative: Mask Function Pattern

For more flexibility, support a mask function:

```python
def get_action_mask_fn(env: gym.Env) -> Callable[[], np.ndarray]:
    """Create action mask function for SB3.

    Args:
        env: UnifiedSimEnv instance

    Returns:
        Function that returns current action mask
    """
    def mask_fn() -> np.ndarray:
        # Access the unwrapped env's last mask
        return env.unwrapped._last_action_mask

    return mask_fn


# Usage with SB3
from sb3_contrib.common.wrappers import ActionMasker

env = UnifiedSimEnv(config)
env = ActionMasker(env, get_action_mask_fn(env))
model = MaskablePPO("MultiInputPolicy", env)
```

### 6. Edge Cases

#### 6.1 All Actions Masked

When no path is feasible (network fully congested):

```python
def step(self, action: int) -> tuple:
    # All actions masked - what happens?
    if not self._current_options or not any(opt.is_feasible for opt in self._current_options):
        # Option 1: Random action from masked set (will fail)
        # Option 2: Return immediate failure without allocation

        # We use Option 1: Let adapter handle it
        result = self._adapter.apply_action(action, ...)
        # adapter returns AllocationResult(success=False, block_reason="ALL_PATHS_BLOCKED")

    # Reward will be negative (blocking penalty)
```

#### 6.2 Fewer Paths Than k

When routing finds fewer than k paths:

```python
# Example: k_paths=3, but only 2 paths found
options = [
    PathOption(path_index=0, is_feasible=True, ...),
    PathOption(path_index=1, is_feasible=False, ...),
    # path_index=2 not present
]

# Mask should be [True, False, False]
mask = compute_action_mask(options, k_paths=3)
# Result: [True, False, False]
```

#### 6.3 Terminal State

At episode end:

```python
def _build_info(self) -> dict:
    if self._current_request is None:
        # All actions masked at terminal state
        mask = np.zeros(self._config.k_paths, dtype=bool)
    # ...
```

### 7. Observation Includes Feasibility

The observation also includes `is_feasible` as a feature:

```python
observation = {
    # ...
    "is_feasible": np.array([1.0, 0.0, 1.0]),  # Same as mask, but float
}

info = {
    "action_mask": np.array([True, False, True]),  # Boolean version
}
```

This redundancy allows:
- `is_feasible` in obs: Agent can learn to predict feasibility
- `action_mask` in info: Hard constraint during action selection

### 8. SB3 MaskablePPO Integration Example

```python
from sb3_contrib import MaskablePPO
from fusion.rl.environments import UnifiedSimEnv, ActionMaskWrapper

# Create environment
config = SimulationConfig.from_file("config.ini")
env = UnifiedSimEnv(config)
env = ActionMaskWrapper(env)

# Create model
model = MaskablePPO(
    "MultiInputPolicy",
    env,
    verbose=1,
    learning_rate=3e-4,
    n_steps=2048,
    batch_size=64,
)

# Train
model.learn(total_timesteps=100_000)

# Evaluate
obs, info = env.reset()
while True:
    action, _ = model.predict(obs, action_masks=env.action_masks())
    obs, reward, terminated, truncated, info = env.step(action)
    if terminated or truncated:
        break
```

### 9. Testing Action Masking

```python
def test_action_mask_matches_feasibility():
    """Action mask should match PathOption.is_feasible."""
    env = UnifiedSimEnv(config)
    obs, info = env.reset(seed=42)

    mask = info["action_mask"]
    is_feas = obs["is_feasible"]

    # Should match (aside from dtype)
    assert np.allclose(mask.astype(float), is_feas)


def test_masked_action_results_in_failure():
    """Selecting a masked action should fail."""
    env = UnifiedSimEnv(config)
    obs, info = env.reset(seed=42)

    mask = info["action_mask"]

    # Find a masked action
    masked_actions = np.where(~mask)[0]
    if len(masked_actions) > 0:
        action = masked_actions[0]
        _, reward, _, _, _ = env.step(action)
        # Should get penalty reward
        assert reward < 0


def test_valid_action_can_succeed():
    """Selecting a valid action can result in success."""
    env = UnifiedSimEnv(config)
    obs, info = env.reset(seed=42)

    mask = info["action_mask"]

    # Find a valid action
    valid_actions = np.where(mask)[0]
    if len(valid_actions) > 0:
        action = valid_actions[0]
        _, reward, _, _, _ = env.step(action)
        # Should get positive reward (if allocation succeeds)
        assert reward > 0


def test_action_mask_wrapper_caches_mask():
    """ActionMaskWrapper should cache action mask."""
    env = UnifiedSimEnv(config)
    env = ActionMaskWrapper(env)

    obs, info = env.reset(seed=42)
    cached = env.action_masks()

    assert np.array_equal(cached, info["action_mask"])
```

## Verification

- [ ] Action mask correctly reflects PathOption.is_feasible
- [ ] Mask is in info dict for both reset() and step()
- [ ] ActionMaskWrapper properly caches mask
- [ ] SB3 MaskablePPO integration works
- [ ] Edge cases handled (all masked, fewer paths, terminal)
- [ ] Tests cover mask generation and usage

## Next Task

Proceed to **P4.2.e** to define the verification plan for UnifiedSimEnv.
