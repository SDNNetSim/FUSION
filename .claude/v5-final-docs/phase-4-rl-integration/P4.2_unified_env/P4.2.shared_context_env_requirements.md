# P4.2 Shared Context - Environment Requirements

**Purpose:** Document Gymnasium API requirements and SB3 integration patterns for UnifiedSimEnv design.

## Source Documentation

- Gymnasium API: https://gymnasium.farama.org/api/env/
- SB3 Action Masking: https://sb3-contrib.readthedocs.io/en/master/modules/ppo_mask.html
- SB3 Custom Environments: https://stable-baselines3.readthedocs.io/en/master/guide/custom_env.html

---

## 1. Gymnasium Env Interface

### Required Methods

```python
class Env:
    """Gymnasium environment interface."""

    observation_space: spaces.Space
    action_space: spaces.Space

    def reset(
        self,
        *,
        seed: int | None = None,
        options: dict | None = None,
    ) -> tuple[ObsType, dict]:
        """Reset environment and return initial observation.

        Returns:
            observation: Initial observation
            info: Auxiliary info dict (must include action_mask)
        """

    def step(
        self,
        action: ActType,
    ) -> tuple[ObsType, float, bool, bool, dict]:
        """Execute action and return result.

        Returns:
            observation: New observation
            reward: Scalar reward
            terminated: Episode ended normally (e.g., all requests processed)
            truncated: Episode ended abnormally (e.g., time limit)
            info: Auxiliary info dict (must include action_mask)
        """
```

### Optional Methods

```python
    def render(self) -> None:
        """Render environment (optional for training)."""

    def close(self) -> None:
        """Clean up resources."""
```

---

## 2. Observation Space Design

### Current GeneralSimEnv Observation

```python
observation_space = spaces.Dict({
    "source": spaces.Box(0, 1, shape=(num_nodes,), dtype=np.float32),
    "destination": spaces.Box(0, 1, shape=(num_nodes,), dtype=np.float32),
    "request_bandwidth": spaces.Box(0, 1, shape=(num_bw_classes,), dtype=np.float32),
    "holding_time": spaces.Box(0, 1, shape=(1,), dtype=np.float32),
    "slots_needed": spaces.Box(-1, max_slots, shape=(k_paths,), dtype=np.float32),
    "path_lengths": spaces.Box(0, max_hops, shape=(k_paths,), dtype=np.float32),
    "paths_cong": spaces.Box(0, 1, shape=(k_paths,), dtype=np.float32),
    "available_slots": spaces.Box(0, 1, shape=(k_paths,), dtype=np.float32),
})
```

### UnifiedSimEnv Observation (Proposed)

```python
observation_space = spaces.Dict({
    # Request features
    "source": spaces.Box(0, 1, shape=(num_nodes,), dtype=np.float32),
    "destination": spaces.Box(0, 1, shape=(num_nodes,), dtype=np.float32),
    "holding_time": spaces.Box(0, 1, shape=(1,), dtype=np.float32),

    # Path features (from PathOption)
    "slots_needed": spaces.Box(-1, max_slots, shape=(k_paths,), dtype=np.float32),
    "path_lengths": spaces.Box(0, max_hops, shape=(k_paths,), dtype=np.float32),
    "congestion": spaces.Box(0, 1, shape=(k_paths,), dtype=np.float32),
    "available_slots": spaces.Box(0, 1, shape=(k_paths,), dtype=np.float32),
    "is_feasible": spaces.Box(0, 1, shape=(k_paths,), dtype=np.float32),
})
```

---

## 3. Action Space Design

```python
# Discrete action space: select one of k candidate paths
action_space = spaces.Discrete(k_paths)

# Action interpretation:
# 0 -> Select shortest path
# 1 -> Select 2nd shortest path
# ...
# k-1 -> Select k-th shortest path
```

---

## 4. Action Masking for SB3

### Pattern: Mask in Info Dict

```python
def reset(self, *, seed=None, options=None):
    # ... initialize episode ...
    obs = self._build_observation()
    info = {
        "action_mask": self._get_action_mask(),
    }
    return obs, info

def step(self, action):
    # ... execute action ...
    obs = self._build_observation()
    info = {
        "action_mask": self._get_action_mask(),
    }
    return obs, reward, terminated, truncated, info
```

### Action Mask Format

```python
def _get_action_mask(self) -> np.ndarray:
    """Return boolean mask of valid actions.

    Returns:
        np.ndarray of shape (k_paths,) where True = valid action
    """
    options = self._adapter.get_path_options(self._current_request, self._network_state)
    return self._adapter.get_action_mask(options)
```

### SB3 ActionMaskWrapper

```python
from sb3_contrib.common.wrappers import ActionMasker

def mask_fn(env):
    """Extract action mask from environment."""
    return env.unwrapped._last_action_mask

# Usage
env = UnifiedSimEnv(config)
env = ActionMasker(env, mask_fn)
model = MaskablePPO("MultiInputPolicy", env)
```

---

## 5. Episode Lifecycle

### Reset Flow

```
reset(seed=42)
  |
  v
Initialize SimulationEngine with seed
  |
  v
Create topology via engine.create_topology()
  |
  v
Generate all requests via engine.generate_requests()
  |
  v
Get first request
  |
  v
Build initial observation from request + path options
  |
  v
Return (obs, {"action_mask": mask})
```

### Step Flow

```
step(action=1)
  |
  v
Apply action via adapter.apply_action(action, request, state, options)
  |
  v
Record result (success/failure) for statistics
  |
  v
Process any releases due before next arrival
  |
  v
Get next request
  |
  v
Build observation from new request + path options
  |
  v
Check termination (all requests processed?)
  |
  v
Return (obs, reward, terminated, truncated, info)
```

---

## 6. Determinism Requirements

### Same Seed = Same Episode

```python
env1 = UnifiedSimEnv(config)
env2 = UnifiedSimEnv(config)

obs1, _ = env1.reset(seed=42)
obs2, _ = env2.reset(seed=42)

assert np.allclose(obs1["source"], obs2["source"])
assert np.allclose(obs1["congestion"], obs2["congestion"])

# Same action sequence produces same rewards
for _ in range(100):
    action = 0
    _, r1, _, _, _ = env1.step(action)
    _, r2, _, _, _ = env2.step(action)
    assert r1 == r2
```

### Seeding Strategy

```python
def reset(self, *, seed=None, options=None):
    super().reset(seed=seed)  # Sets self.np_random

    # Pass seed to simulation engine
    self._engine.init_iteration(seed=seed or 0)
    self._engine.create_topology()
    self._engine.generate_requests()
```

---

## 7. Integration with SimulationEngine

### Required Engine Methods

```python
class SimulationEngine:
    """Methods needed by UnifiedSimEnv."""

    def init_iteration(self, seed: int) -> None:
        """Initialize for new episode with seed."""

    def create_topology(self) -> None:
        """Create network topology."""

    def generate_requests(self) -> None:
        """Generate all requests for episode."""

    def get_next_request(self) -> Request | None:
        """Get next request to process, or None if done."""

    def process_releases_until(self, time: float) -> None:
        """Process all releases due before given time."""

    @property
    def network_state(self) -> NetworkState:
        """Current network state."""
```

---

## 8. Compatibility with Legacy Scripts

### Feature Flag for Gradual Migration

```python
# Environment variable or config option
USE_UNIFIED_ENV = os.environ.get("USE_UNIFIED_ENV", "0") == "1"

def create_env(config):
    if USE_UNIFIED_ENV:
        from fusion.rl.environments import UnifiedSimEnv
        return UnifiedSimEnv(config)
    else:
        from fusion.modules.rl.gymnasium_envs import SimEnv
        return SimEnv(sim_dict=config.to_legacy_dict())
```

---

## 9. Key Differences from GeneralSimEnv

| Aspect | GeneralSimEnv | UnifiedSimEnv |
|--------|---------------|---------------|
| Simulation | engine_obj (legacy) | SimulationEngine (V4) |
| Routing | Separate route_obj | Via adapter.routing_pipeline |
| Feasibility | mock_handle_arrival | Via adapter.spectrum_pipeline |
| Allocation | engine_obj.handle_arrival | Via adapter.apply_action |
| State | engine_props dict | NetworkState object |
| Paths | paths_matrix | list[PathOption] |

---

## 10. Testing Requirements

### Gymnasium Checker

```python
from gymnasium.utils.env_checker import check_env

env = UnifiedSimEnv(config)
check_env(env)  # Must pass without warnings
```

### Episode Smoke Test

```python
def test_episode_completes():
    env = UnifiedSimEnv(config)
    obs, info = env.reset(seed=42)

    done = False
    total_reward = 0
    while not done:
        action = env.action_space.sample()
        obs, reward, terminated, truncated, info = env.step(action)
        done = terminated or truncated
        total_reward += reward

    assert total_reward != 0  # Some allocations happened
```
